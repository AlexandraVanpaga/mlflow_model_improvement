Здравствуйте!



Здесь лежит проект по улучшению Baseline-модели ля определения цен на недвижимость.
Цель: улучшить базовую catboost-модель через отбор фичей и настройку гиперпараметров.
Данные: датасет с инфо о недвижимости в г. Москва.
Доступ к проекту:
git clone https://github.com/AlexandraVanpaga/mle-project-sprint-2-v001.git
cd mle-project-sprint-2-v001
pip install -r requirements.txt

бакет: s3-student-mle-20250729-0060996a6e-freetrack

ЭТАП 1:

- Инструкция по поднятию Mlflow: запускается командой sh run_mlflow.sh
- id эксперимента с базовой моделью в MLflow: 7
- название эксперимента с базовой моделью в Mlflow: baseline_model_experiment
- Залогирована базовая модель, метрики, initial_data, параметры из файла params.yaml

ЭТАП 2:
Уже на этом этапе добавила дополнительные колонки (округ, район, удаление от центра Москвы, десятилетие построения здания, находится и квартира на первом этаже, находится ли квартира на последнем этаже, отноешнеи жилой площади к общей, плотность квартир на этаже), так как это нужно для понимания закономерностей.
- id эксперимента с EDA в MLflow: 9
- название эксперимента в Mlflow: EDA_artifacts
- залогированы графики, данные, маркдаун с выводами и ноутбук

ЭТАП 3:
На этом этапе была произведена нормализация числовых колонок и автогенерация признаков. На обогащенном датасете модель повела себя немного лучше: ошибка в реальных единицах упала приблизительно на 200 000 рублей и r^2 упал на несколько десятых.

- id эксперимента с генерацией в MLflow: 10
- название эксперимента в Mlflow: feature_generation
- id эксперимента с preprocessing_pipeline в MLflow: 24
- название эксперимента с preprocessing_pipeline в Mlflow: feature_generation
- залогировала параметры, метрики, данные и ноутбук
- название зарегистрированной модели: FeatureGen_CatBoost_Model

ЭТАП 4:
На этом этапе был произведен отбор признаков через Sequential Forward Selection и Sequential Forward Floating Selection, а затем еще через важность признаков по catboost. На отобранных признаках модель повела себя немного лучше: ошибка в реальных единицах на тренировочном сете на 500 000 приблизительно, и r^2 колеблется возле 0.8.

- id эксперимента с отбором признаков в MLflow: 11
- название эксперимента в Mlflow: feature_selection
- залогировала параметры, метрики, данные и ноутбук
- название зарегистрированной модели: FeatureSelectionCatBoostCombined

ЭТАП 5:
На этом этапе был произведен отбор гиперпараметров через Optuna и через RandomizedSearchCV. Этот отбор обучался на всем тренировочном сете, а затем проверялся на валидационном сете. А затем финальная версия с финальными признаками и параметрами обучилась на валидационном и тренировочном сетах, и проверилась на тесте. Заключение такое: На отобранных гиперпараметрах на тесте модель повела себя хуже: MAE: 2925401.70 , R2: 0.6683. Ошиба в реальных единиц совсем чуть-чуть нижеit  базовой модели. НО: trials и n_iter ставила 2, иначе это очень далко, на текущих мощностях не вариант. Теоретически может улучшиться перформанс модели.

- id эксперимента с отбором гиперпараметров через Optuna в MLflow: 17
- id эксперимента с отбором гиперпараметров через RandomizedSearchCV в MLflow: 15
- id эксперимента с обучением финальной модели в MLflow: 19
- название эксперимента с отбором гиперпараметров через Optuna в Mlflow: catboost_optuna_price
- название эксперимента с отбором гиперпараметров через RandomizedSearchCV в Mlflow: catboost_random_search
- название эксперимента с обучением финальной модели Mlflow: catboost_best_model
- залогировала параметры, метрики, данные и ноутбук
- название зарегистрированной финальной модели: catboost_best_model



